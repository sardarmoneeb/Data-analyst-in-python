{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e304d3-cac2-4eb0-a046-a8d488b609ab",
   "metadata": {},
   "source": [
    "File title basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7d3f6-7f41-4675-99ce-68e549ddc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    r\"D:\\Kaggle datasets\\title.basics.tsv.gz\",\n",
    "    sep=\"\\t\",\n",
    "    na_values=\"\\\\N\",\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc498c0-7e07-4fa0-904c-1588033114b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>short</td>\n",
       "      <td>Poor Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>0</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType            primaryTitle           originalTitle  \\\n",
       "0  tt0000001     short              Carmencita              Carmencita   \n",
       "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "2  tt0000003     short            Poor Pierrot          Pauvre Pierrot   \n",
       "3  tt0000004     short             Un bon bock             Un bon bock   \n",
       "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "   isAdult  startYear  endYear runtimeMinutes                    genres  \n",
       "0        0     1894.0      NaN              1         Documentary,Short  \n",
       "1        0     1892.0      NaN              5           Animation,Short  \n",
       "2        0     1892.0      NaN              5  Animation,Comedy,Romance  \n",
       "3        0     1892.0      NaN             12           Animation,Short  \n",
       "4        0     1893.0      NaN              1                     Short  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3e5dd73-76df-483b-a951-7b7f3ad2195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned CSV ready for MySQL (numeric blanks safe)\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"D:/Kaggle datasets/title.basics.tsv.gz\"\n",
    "\n",
    "# Load limited rows\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "   tconst,\n",
    "   titleType,\n",
    "   primaryTitle,\n",
    "   originalTitle,\n",
    "   isAdult,\n",
    "   startYear,\n",
    "   endYear,\n",
    "   runtimeMinutes,\n",
    "   genres\n",
    "FROM read_csv_auto('{file_path}', delim='\\t', header=True, nullstr='\\\\N')\n",
    "LIMIT 10000\n",
    "\"\"\"\n",
    "df = duckdb.sql(query).df()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Strip string columns\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "# Replace empty strings / \\N with pd.NA before converting numeric\n",
    "df = df.replace(r'^\\s*$', pd.NA, regex=True)\n",
    "df = df.replace('\\\\N', pd.NA)\n",
    "\n",
    "# Numeric columns → Int64 (nullable)\n",
    "numeric_cols = [\"isAdult\", \"startYear\", \"endYear\", \"runtimeMinutes\"]\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')  # blanks -> NA\n",
    "\n",
    "# String columns → fill optional\n",
    "string_cols = [\"titleType\", \"primaryTitle\", \"originalTitle\", \"genres\"]\n",
    "df[string_cols] = df[string_cols].fillna(\"Unknown\")\n",
    "\n",
    "# Save CSV for MySQL → blanks exported as empty (safe for numeric)\n",
    "df.to_csv(\n",
    "    \"D:/Kaggle datasets/title_basics_clean_mysql.csv\",\n",
    "    index=False,\n",
    "    quoting=0,    # No quotes\n",
    "    na_rep=''     # blanks → empty → MySQL will read as NULL\n",
    ")\n",
    "\n",
    "print(\"✅ Cleaned CSV ready for MySQL (numeric blanks safe)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecdcf832-f2e8-44de-9186-6e72697863c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting duckdb\n",
      "  Downloading duckdb-1.3.2-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "Downloading duckdb-1.3.2-cp312-cp312-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.4 MB 4.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.1/11.4 MB 4.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.1/11.4 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.4 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.4 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.1/11.4 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.1/11.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.9/11.4 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.4 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.4 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.4 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.4 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 2.6 MB/s  0:00:04\n",
      "Installing collected packages: duckdb\n",
      "Successfully installed duckdb-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install duckdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f93544-e2e0-4c31-94d9-5d3da740c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f71cf-7480-408b-8b2a-b1f676391b8a",
   "metadata": {},
   "source": [
    "File title akas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650d0ece-2cb5-4671-a4fd-35c20690161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning complete. File saved at: D:/Kaggle datasets/title_akas_sample_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your IMDb file\n",
    "file_path = r\"D:/Kaggle datasets/title.akas.tsv.gz\"\n",
    "\n",
    "# Query with LIMIT to avoid memory issues\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        titleId,\n",
    "        ordering,\n",
    "        title,\n",
    "        region,\n",
    "        language,\n",
    "        types,\n",
    "        attributes,\n",
    "        CAST(isOriginalTitle AS INTEGER) AS isOriginalTitle\n",
    "    FROM read_csv_auto('{file_path}', delim='\\t', header=True, nullstr='\\\\N')\n",
    "    LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and fetch as pandas DataFrame\n",
    "df = duckdb.sql(query).df()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Save cleaned sample to CSV\n",
    "output_path = r\"D:/Kaggle datasets/title_akas_sample_clean.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"✅ Cleaning complete. File saved at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc76d7d-adc3-4dae-a175-7edeb68e6159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning complete. File saved at: D:/Kaggle datasets/title_akas_sample_clean.csv\n",
      "🔎 Data types after cleaning:\n",
      " titleId              object\n",
      "ordering              Int64\n",
      "title                object\n",
      "region             category\n",
      "language           category\n",
      "types              category\n",
      "attributes         category\n",
      "isOriginalTitle       Int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your IMDb file\n",
    "file_path = r\"D:/Kaggle datasets/title.akas.tsv.gz\"\n",
    "\n",
    "# Query with LIMIT to avoid memory issues\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        titleId,\n",
    "        ordering,\n",
    "        title,\n",
    "        region,\n",
    "        language,\n",
    "        types,\n",
    "        attributes,\n",
    "        CAST(isOriginalTitle AS INTEGER) AS isOriginalTitle\n",
    "    FROM read_csv_auto('{file_path}', delim='\\t', header=True, nullstr='\\\\N')\n",
    "    LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and fetch as pandas DataFrame\n",
    "df = duckdb.sql(query).df()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# -----------------------------\n",
    "# Handle NULL values\n",
    "# -----------------------------\n",
    "# Option 1: Drop rows with any NULLs\n",
    "# df = df.dropna()\n",
    "\n",
    "# Option 2: Fill missing values\n",
    "df = df.fillna({\n",
    "    \"region\": \"Unknown\",\n",
    "    \"language\": \"Unknown\",\n",
    "    \"types\": \"Unknown\",\n",
    "    \"attributes\": \"None\",\n",
    "    \"title\": \"Untitled\"\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# Fix dtypes\n",
    "# -----------------------------\n",
    "df[\"ordering\"] = pd.to_numeric(df[\"ordering\"], errors=\"coerce\").astype(\"Int64\")   # integer but allows NaN\n",
    "df[\"isOriginalTitle\"] = df[\"isOriginalTitle\"].astype(\"Int64\")  # integer 0/1\n",
    "df[\"region\"] = df[\"region\"].astype(\"category\")\n",
    "df[\"language\"] = df[\"language\"].astype(\"category\")\n",
    "df[\"types\"] = df[\"types\"].astype(\"category\")\n",
    "df[\"attributes\"] = df[\"attributes\"].astype(\"category\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save cleaned sample to CSV\n",
    "# -----------------------------\n",
    "output_path = r\"D:/Kaggle datasets/title_akas_sample_clean.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"✅ Cleaning complete. File saved at:\", output_path)\n",
    "print(\"🔎 Data types after cleaning:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e1ed2-a47e-4b31-849a-6b1c82b65741",
   "metadata": {},
   "source": [
    "File title crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbfdd0a3-7a1b-4598-b6dd-2ad0f8807ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst  directors    writers\n",
      "0  tt0000001  nm0005690        NaN\n",
      "1  tt0000002  nm0721526        NaN\n",
      "2  tt0000003  nm0721526  nm0721526\n",
      "3  tt0000004  nm0721526        NaN\n",
      "4  tt0000005  nm0005690        NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r\"D:\\Kaggle datasets\\title.crew.tsv.gz\",\n",
    "    sep=\"\\t\",\n",
    "    na_values=\"\\\\N\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Now preview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db17a86-7a42-4513-a0c6-a81fc9398a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning complete. File saved at: D:/Kaggle datasets/title_crew_sample_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your IMDb file\n",
    "file_path = r\"D:/Kaggle datasets/title.crew.tsv.gz\"\n",
    "\n",
    "# Query with LIMIT to avoid memory issues\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        tconst,\n",
    "        directors,\n",
    "        writers,\n",
    "    FROM read_csv_auto('{file_path}', delim='\\t', header=True, nullstr='\\\\N')\n",
    "    LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and fetch as pandas DataFrame\n",
    "df = duckdb.sql(query).df()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# -----------------------------\n",
    "# Handle NULL values\n",
    "# -----------------------------\n",
    "# Option 1: Drop rows with any NULLs\n",
    "# df = df.dropna()\n",
    "\n",
    "# Option 2: Fill missing values\n",
    "df = df.fillna({\n",
    "    \"directors\": \"Unknown\",\n",
    "    \"writers\": \"Unknown\",\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# Fix dtypes\n",
    "# -----------------------------\n",
    "# df[\"ordering\"] = pd.to_numeric(df[\"ordering\"], errors=\"coerce\").astype(\"Int64\")   # integer but allows NaN\n",
    "# df[\"isOriginalTitle\"] = df[\"isOriginalTitle\"].astype(\"Int64\")  # integer 0/1\n",
    "# df[\"region\"] = df[\"region\"].astype(\"category\")\n",
    "# df[\"language\"] = df[\"language\"].astype(\"category\")\n",
    "# df[\"types\"] = df[\"types\"].astype(\"category\")\n",
    "# df[\"attributes\"] = df[\"attributes\"].astype(\"category\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save cleaned sample to CSV\n",
    "# -----------------------------\n",
    "output_path = r\"D:/Kaggle datasets/title_crew_sample_clean.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"✅ Cleaning complete. File saved at:\", output_path)\n",
    "# print(\"🔎 Data types after cleaning:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03446b41-72f3-4f31-a30e-26fb9f5a113f",
   "metadata": {},
   "source": [
    "File title episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42824c49-22e9-4845-ac06-72e0adc49d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst parentTconst  seasonNumber  episodeNumber\n",
      "0  tt0031458   tt32857063           NaN            NaN\n",
      "1  tt0041951    tt0041038           1.0            9.0\n",
      "2  tt0042816    tt0989125           1.0           17.0\n",
      "3  tt0042889    tt0989125           NaN            NaN\n",
      "4  tt0043426    tt0040051           3.0           42.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r\"D:\\Kaggle datasets\\title.episode.tsv.gz\",\n",
    "    sep=\"\\t\",\n",
    "    na_values=\"\\\\N\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Now preview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af92b706-ce5f-45d7-8a83-104e987f3e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning complete. File saved at: D:/Kaggle datasets/title_episode_sample_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your IMDb file\n",
    "file_path = r\"D:/Kaggle datasets/title.episode.tsv.gz\"\n",
    "\n",
    "# Query with LIMIT to avoid memory issues\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        tconst,\n",
    "        parentTconst,\n",
    "        seasonNumber,\n",
    "        episodeNumber,\n",
    "    FROM read_csv_auto('{file_path}', delim='\\t', header=True, nullstr='\\\\N')\n",
    "    LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and fetch as pandas DataFrame\n",
    "df = duckdb.sql(query).df()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# -----------------------------\n",
    "# Handle NULL values\n",
    "# -----------------------------\n",
    "# Option 1: Drop rows with any NULLs\n",
    "df = df.dropna()\n",
    "\n",
    "# Option 2: Fill missing values\n",
    "# df = df.fillna({\n",
    "#     \"seasonNumber\": \"Null\",\n",
    "#     \"wepisodeNumber\": \"Null\",\n",
    "# })\n",
    "\n",
    "# -----------------------------\n",
    "# Fix dtypes\n",
    "# -----------------------------\n",
    "# df[\"ordering\"] = pd.to_numeric(df[\"ordering\"], errors=\"coerce\").astype(\"Int64\")   # integer but allows NaN\n",
    "# df[\"isOriginalTitle\"] = df[\"isOriginalTitle\"].astype(\"Int64\")  # integer 0/1\n",
    "# df[\"region\"] = df[\"region\"].astype(\"category\")\n",
    "# df[\"language\"] = df[\"language\"].astype(\"category\")\n",
    "# df[\"types\"] = df[\"types\"].astype(\"category\")\n",
    "# df[\"attributes\"] = df[\"attributes\"].astype(\"category\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save cleaned sample to CSV\n",
    "# -----------------------------\n",
    "output_path = r\"D:/Kaggle datasets/title_episode_sample_clean.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"✅ Cleaning complete. File saved at:\", output_path)\n",
    "# print(\"🔎 Data types after cleaning:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262ce23-e546-49d5-9323-5804b9bfc7c9",
   "metadata": {},
   "source": [
    "File title ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4316747-e6f7-4b5f-b2b2-6345838539c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst  averageRating  numVotes\n",
      "0  tt0000001            5.7      2178\n",
      "1  tt0000002            5.5       299\n",
      "2  tt0000003            6.4      2243\n",
      "3  tt0000004            5.2       193\n",
      "4  tt0000005            6.2      2988\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r\"D:\\Kaggle datasets\\title.ratings.tsv.gz\",\n",
    "    sep=\"\\t\",\n",
    "    na_values=\"\\\\N\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Now preview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81130f09-3c79-4e45-8b0f-8c352df1a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning complete. File saved at: D:/Kaggle datasets/title_ratings_sample_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your IMDb file\n",
    "file_path = r\"D:/Kaggle datasets/title.ratings.tsv.gz\"\n",
    "\n",
    "# Query with LIMIT to avoid memory issues\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        tconst,\n",
    "        averageRating,\n",
    "        numVotes,\n",
    "    FROM read_csv_auto('{file_path}', delim='\\t', header=True, nullstr='\\\\N')\n",
    "    LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and fetch as pandas DataFrame\n",
    "df = duckdb.sql(query).df()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# -----------------------------\n",
    "# Handle NULL values\n",
    "# -----------------------------\n",
    "# Option 1: Drop rows with any NULLs\n",
    "df = df.dropna()\n",
    "\n",
    "# Option 2: Fill missing values\n",
    "# df = df.fillna({\n",
    "#     \"seasonNumber\": \"Null\",\n",
    "#     \"wepisodeNumber\": \"Null\",\n",
    "# })\n",
    "\n",
    "# -----------------------------\n",
    "# Fix dtypes\n",
    "# -----------------------------\n",
    "# df[\"ordering\"] = pd.to_numeric(df[\"ordering\"], errors=\"coerce\").astype(\"Int64\")   # integer but allows NaN\n",
    "# df[\"isOriginalTitle\"] = df[\"isOriginalTitle\"].astype(\"Int64\")  # integer 0/1\n",
    "# df[\"region\"] = df[\"region\"].astype(\"category\")\n",
    "# df[\"language\"] = df[\"language\"].astype(\"category\")\n",
    "# df[\"types\"] = df[\"types\"].astype(\"category\")\n",
    "# df[\"attributes\"] = df[\"attributes\"].astype(\"category\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save cleaned sample to CSV\n",
    "# -----------------------------\n",
    "output_path = r\"D:/Kaggle datasets/title_ratings_sample_clean.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"✅ Cleaning complete. File saved at:\", output_path)\n",
    "# print(\"🔎 Data types after cleaning:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd14a33-f38c-41d2-9c9a-1185a9a9736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "File title principals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538befba-6adb-4f6b-8d55-5c98ac955109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r\"D:\\Kaggle datasets\\title.principals.tsv.gz\",\n",
    "    sep=\"\\t\",\n",
    "    na_values=\"\\\\N\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Now preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41185df4-b72b-40b6-bea2-3f1ddc1c5d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>ordering</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94747062</th>\n",
       "      <td>tt9916880</td>\n",
       "      <td>17</td>\n",
       "      <td>nm0996406</td>\n",
       "      <td>director</td>\n",
       "      <td>principal director</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94747063</th>\n",
       "      <td>tt9916880</td>\n",
       "      <td>18</td>\n",
       "      <td>nm1482639</td>\n",
       "      <td>writer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94747064</th>\n",
       "      <td>tt9916880</td>\n",
       "      <td>19</td>\n",
       "      <td>nm2586970</td>\n",
       "      <td>writer</td>\n",
       "      <td>books</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94747065</th>\n",
       "      <td>tt9916880</td>\n",
       "      <td>20</td>\n",
       "      <td>nm1594058</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94747066</th>\n",
       "      <td>tt9916880</td>\n",
       "      <td>21</td>\n",
       "      <td>nm1482639</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tconst  ordering     nconst  category                 job  \\\n",
       "94747062  tt9916880        17  nm0996406  director  principal director   \n",
       "94747063  tt9916880        18  nm1482639    writer                 NaN   \n",
       "94747064  tt9916880        19  nm2586970    writer               books   \n",
       "94747065  tt9916880        20  nm1594058  producer            producer   \n",
       "94747066  tt9916880        21  nm1482639  producer            producer   \n",
       "\n",
       "         characters  \n",
       "94747062        NaN  \n",
       "94747063        NaN  \n",
       "94747064        NaN  \n",
       "94747065        NaN  \n",
       "94747066        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554e5b5d-f004-408c-9c6a-92bf45217cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning complete. File saved at: D:/Kaggle datasets/title_principal_sample_clean.csv\n",
      "🔎 Data types after cleaning:\n",
      " tconst                object\n",
      "ordering               Int64\n",
      "nconst                object\n",
      "category            category\n",
      "job           string[python]\n",
      "characters    string[python]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"D:/Kaggle datasets/title.principals.tsv.gz\"\n",
    "\n",
    "# Query with LIMIT to avoid memory issues\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        tconst,\n",
    "        ordering,\n",
    "        nconst,\n",
    "        category,\n",
    "        job,\n",
    "        characters\n",
    "    FROM read_csv_auto('{file_path}', delim='\\t', header=True, nullstr='\\\\N')\n",
    "    LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and fetch as pandas DataFrame\n",
    "df = duckdb.sql(query).df()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# -----------------------------\n",
    "# Handle NULL values\n",
    "# -----------------------------\n",
    "# Option 1: Drop rows with all NULLs in critical columns\n",
    "df = df.dropna(subset=['tconst', 'nconst'])  # optional\n",
    "# Option 2: Fill missing values (if needed)\n",
    "# df = df.fillna({\"job\": \"Unknown\", \"characters\": \"Unknown\"})\n",
    "\n",
    "# -----------------------------\n",
    "# Fix dtypes\n",
    "# -----------------------------\n",
    "df[\"ordering\"] = pd.to_numeric(df[\"ordering\"], errors=\"coerce\").astype(\"Int64\")  # nullable int\n",
    "df[\"category\"] = df[\"category\"].astype(\"category\")\n",
    "df[\"job\"] = df[\"job\"].astype(\"string\")\n",
    "df[\"characters\"] = df[\"characters\"].astype(\"string\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save cleaned sample to CSV\n",
    "# -----------------------------\n",
    "output_path = r\"D:/Kaggle datasets/title_principal_sample_clean.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"✅ Cleaning complete. File saved at:\", output_path)\n",
    "print(\"🔎 Data types after cleaning:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871eb2d-d866-4eb8-b199-64c186b267a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
